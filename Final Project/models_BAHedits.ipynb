{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "#!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "#!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data analysis\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "#visualising \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as patches\n",
    "import shap\n",
    "\n",
    "#ml\n",
    "import lightgbm as lgb\n",
    "import lightgbm as LGBMRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, AdaBoostClassifier \n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from plotly import tools, subplots\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "py.init_notebook_mode(connected=True)\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "pd.set_option('max_columns', 200)\n",
    "pd.set_option('max_rows', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diagnosis-of-covid-19-and-its-clinical-spectrum.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "# df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "# df = df.dropna()\n",
    "df.columns = [x.lower().strip().replace(' ','_') for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Size of the data', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform target variable into numeric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['sars_cov_2_exam_result'] = df['sars_cov_2_exam_result'].replace(['negative','positive'], [0,1])\n",
    "#sns.countplot(df['sars_cov_2_exam_result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"There are {}% target values with 1\".format(100 *df['sars_cov_2_exam_result'].value_counts()[1]/df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Examine missing values\n",
    "# def missing_data(data):\n",
    "#     total = data.isnull().sum()\n",
    "#     percent = (data.isnull().sum()/data.isnull().count()*100)\n",
    "#     tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "#     types = []\n",
    "#     for col in data.columns:\n",
    "#         dtype = str(data[col].dtype)\n",
    "#         types.append(dtype)\n",
    "#     tt['Types'] = types\n",
    "#     return(np.transpose(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handling missing values \n",
    "#!pip install quilt\n",
    "#import missingno as msno\n",
    "#The msno.matrix nullity matrix is a data-dense display which lets you quickly visually analyse data completion.\n",
    "#msno.matrix(df.head(20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The missingno correlation heatmap measures nullity correlation: \n",
    "#how strongly the presence or absence of one variable affects the presence of another:\n",
    "\n",
    "#a = msno.heatmap(df, sort='ascending')\n",
    "#a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dendrogram allows you to more fully correlate variable completion, \n",
    "#revealing trends deeper than the pairwise ones visible in the correlation heatmap:\n",
    "\n",
    "#a2 = msno.dendrogram(df)\n",
    "#a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of each type of column\n",
    "#df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id                                            5644\n",
       "sars_cov_2_exam_result                                   2\n",
       "patient_addmited_to_regular_ward_1_yes_0_no              2\n",
       "patient_addmited_to_semi_intensive_unit_1_yes_0_no       2\n",
       "patient_addmited_to_intensive_care_unit_1_yes_0_no       2\n",
       "respiratory_syncytial_virus                              2\n",
       "influenza_a                                              2\n",
       "influenza_b                                              2\n",
       "parainfluenza_1                                          2\n",
       "coronavirusnl63                                          2\n",
       "rhinovirus_enterovirus                                   2\n",
       "coronavirus_hku1                                         2\n",
       "parainfluenza_3                                          2\n",
       "chlamydophila_pneumoniae                                 2\n",
       "adenovirus                                               2\n",
       "parainfluenza_4                                          2\n",
       "coronavirus229e                                          2\n",
       "coronavirusoc43                                          2\n",
       "inf_a_h1n1_2009                                          2\n",
       "bordetella_pertussis                                     2\n",
       "metapneumovirus                                          2\n",
       "parainfluenza_2                                          1\n",
       "influenza_b_rapid_test                                   2\n",
       "influenza_a_rapid_test                                   2\n",
       "strepto_a                                                3\n",
       "myeloblasts                                              1\n",
       "urine_esterase                                           2\n",
       "urine_aspect                                             4\n",
       "urine_ph                                                11\n",
       "urine_hemoglobin                                         3\n",
       "urine_bile_pigments                                      2\n",
       "urine_ketone_bodies                                      2\n",
       "urine_nitrite                                            1\n",
       "urine_urobilinogen                                       2\n",
       "urine_protein                                            2\n",
       "urine_leukocytes                                        31\n",
       "urine_crystals                                           5\n",
       "urine_hyaline_cylinders                                  1\n",
       "urine_granular_cylinders                                 1\n",
       "urine_yeasts                                             1\n",
       "urine_color                                              4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of unique classes in each object column\n",
    "df.select_dtypes('object').apply(pd.Series.nunique, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have dealt with the categorical variables and the outliers, let's continue with the EDA. One way to try and understand the data is by looking for correlations between the features and the target. We can calculate the Pearson correlation coefficient between every variable and the target using the .corr dataframe method.\n",
    "\n",
    "#The correlation coefficient is not the greatest method to represent \"relevance\" of a feature, but it does give us an idea of possible relationships within the data. Some general interpretations of the absolute value of the correlation coefficent are:\n",
    "\n",
    "#00-.19 “very weak”\n",
    "#.20-.39 “weak”\n",
    "#.40-.59 “moderate”\n",
    "#.60-.79 “strong”\n",
    "#.80-1.0 “very strong”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Correlations\n",
    "# Find correlations with the target and sort\n",
    "#correlations = df.corr()['sars_cov_2_exam_result'].sort_values()\n",
    "\n",
    "# Display correlations\n",
    "#print('Most Positive Correlations:\\n', correlations.tail(15))\n",
    "#print('\\nMost Negative Correlations:\\n', correlations.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#first ten correlations between the features in dataset\n",
    "features = df.columns.values[2:112]\n",
    "corrs_ = df[features].corr().abs().unstack().sort_values(kind=\"quicksort\").reset_index()\n",
    "corrs_ = corrs_[corrs_['level_0'] != corrs_['level_1']]\n",
    "#corrs_.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrs_.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The correlation between the features is small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlations clustermap\n",
    "# corrs = df.corr()\n",
    "# plt.figure(figsize = (20, 8))\n",
    "# # Heatmap of correlations\n",
    "# sns.heatmap(corrs, cmap = plt.cm.RdYlBu_r, vmin = -0.25, annot = False, vmax = 0.8)\n",
    "# plt.title('Clustermap');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make some visuals\n",
    "# def plot_dist_col(column):\n",
    "#     pos__df = df[df['sars_cov_2_exam_result'] ==1]\n",
    "#     neg__df = df[df['sars_cov_2_exam_result'] ==0]\n",
    "\n",
    "#     '''plot dist curves for train and test weather data for the given column name'''\n",
    "#     fig, ax = plt.subplots(figsize=(10, 10))\n",
    "#     sns.distplot(pos__df[column].dropna(), color='green', ax=ax).set_title(column, fontsize=16)\n",
    "#     sns.distplot(neg__df[column].dropna(), color='purple', ax=ax).set_title(column, fontsize=16)\n",
    "#     plt.xlabel(column, fontsize=15)\n",
    "#     plt.legend(['Positive sars cov 2 exam result', 'Negative sars cov 2 exam result'])\n",
    "#     plt.show()\n",
    "# plot_dist_col('patient_age_quantile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.pie( values=df.groupby(['sars_cov_2_exam_result']).size().values,names=df.groupby(['sars_cov_2_exam_result']).size().index)\n",
    "# fig.update_layout(\n",
    "#     font=dict(\n",
    "#         size=15,\n",
    "#         color=\"black\" ) )   \n",
    "# py.iplot(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding variables: find a way to encode (represent) these variables as numbers before handing them off to the model\n",
    "\n",
    "#fill in mean for floats\n",
    "for c in df.columns:\n",
    "    if df[c].dtype=='float16' or  df[c].dtype=='float32' or  df[c].dtype=='float64':\n",
    "        df[c].fillna(df[c].mean())\n",
    "\n",
    "#fill in -999 for categoricals\n",
    "df = df.fillna(-999)\n",
    "# Label Encoding\n",
    "for f in df.columns:\n",
    "    if df[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(df[f].values))\n",
    "        df[f] = lbl.transform(list(df[f].values))\n",
    "        \n",
    "#print('Labelling done.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##feature selection \n",
    "## Find the optimal feature subset using an evaluation measure. \n",
    "#The choice of evaluation metric distinguish the three main strategies \n",
    "#of feature selection algorithms: the wrapper strategy, the filter \n",
    "#strategy, and the embedded strategy\n",
    "\n",
    "#Filter methods:\n",
    "\n",
    "#information gain\n",
    "#chi-square test\n",
    "#correlation coefficient\n",
    "#variance threshold\n",
    "\n",
    "#Wrapper methods:\n",
    "#recursive feature elimination\n",
    "#sequential feature selection algorithms\n",
    "\n",
    "#Embedded methods:\n",
    "#L1 (LASSO) regularization\n",
    "#decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In our case, we remove some useless, redundant variables. \n",
    "#We will use three methods for feature selection: \n",
    "#Remove collinear features, remove features with greater than a \n",
    "#threshold percentage of missing values, keep only the most relevant \n",
    "#features using feature importances from a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove collinear varialbe: variables that highly correlated to one another \n",
    "#can decrease model's availability to learn, decrease model interpretability and \n",
    "#decrease generalization performance on the test set\n",
    "\n",
    "# Threshold for removing correlated variables\n",
    "threshold = 0.92\n",
    "\n",
    "# Absolute value correlation matrix\n",
    "corr_matrix = df.corr().abs()\n",
    "corr_matrix.head()\n",
    "# Upper triangle of correlations\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "#upper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns with correlations above threshold\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "# print('There are %d columns to remove.' % (len(to_drop)))\n",
    "dataset = df.drop(columns = to_drop)\n",
    "# print('Data shape: ', dataset.shape)\n",
    "# print('Size of the data', dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove missing values\n",
    "#dataset missing values (in percent)\n",
    "dataset_missing = (dataset.isnull().sum() / len(dataset)).sort_values(ascending = False)\n",
    "#dataset_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify missing values above threshold\n",
    "dataset_missing_ = dataset_missing.index[dataset_missing > 0.85]\n",
    "\n",
    "all_missing = list(set(dataset_missing_))\n",
    "#print('There are %d columns with more than 85%% missing values' % len(all_missing))\n",
    "dataset = dataset.drop(columns = all_missing)\n",
    "#print('Data shape: ', dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection through feature importance\n",
    "cat_features = [i for i in dataset.columns if str(dataset[i].dtype) in ['object', 'category']]\n",
    "\n",
    "if len(cat_features) > 0:\n",
    "    dataset[cat_features] = dataset[cat_features].astype('category')\n",
    "\n",
    "\n",
    "df_lgb = dataset.copy()\n",
    "for i in cat_features:\n",
    "    df_lgb[i] = dataset[i].cat.codes\n",
    "\n",
    "df_lgb.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in df_lgb.columns]\n",
    "\n",
    "dataset_labels = df_lgb['sars_cov_2_exam_result']\n",
    "df_lgb_ = df_lgb.copy()\n",
    "df_lgb = df_lgb.drop(['patient_id', \n",
    "                      'sars_cov_2_exam_result', \n",
    "                      'patient_addmited_to_regular_ward_1_yes_0_no',\n",
    "                      'patient_addmited_to_semi_intensive_unit_1_yes_0_no',\n",
    "                      'patient_addmited_to_intensive_care_unit_1_yes_0_no'\n",
    "                ], axis=1)\n",
    "x = df_lgb.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.649972\tvalid_0's binary_logloss: 0.610572\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.603197\tvalid_0's binary_logloss: 0.643876\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty array to hold feature importances\n",
    "feature_importances = np.zeros(df_lgb.shape[1])\n",
    "\n",
    "# Create the model with several hyperparameters\n",
    "model = lgb.LGBMClassifier(objective='binary', boosting_type = 'goss', n_estimators = 5000, class_weight = 'balanced')\n",
    "\n",
    "# Fit the model twice to avoid overfitting\n",
    "for i in range(2):\n",
    "    # Split into training and validation set\n",
    "    dataset_features, valid_features, dataset_features_y, valid_y = train_test_split(x, dataset_labels, test_size = 0.20, random_state = i)\n",
    "    \n",
    "    # Train using early stopping\n",
    "    model.fit(dataset_features, dataset_features_y, early_stopping_rounds=100, eval_set = [(valid_features, valid_y)], \n",
    "              eval_metric = 'auc', verbose = 200)\n",
    "    \n",
    "    # Record the feature importances\n",
    "    feature_importances += model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patient_age_quantile</td>\n",
       "      <td>276.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neutrophils</td>\n",
       "      <td>45.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>proteina_c_reativa_mg_dl</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hematocrit</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>respiratory_syncytial_virus</td>\n",
       "      <td>26.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature  importance\n",
       "0         patient_age_quantile       276.5\n",
       "5                  neutrophils        45.5\n",
       "7     proteina_c_reativa_mg_dl        33.5\n",
       "1                   hematocrit        29.0\n",
       "3  respiratory_syncytial_virus        26.5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average feature importances! \n",
    "feature_importances = feature_importances / 2\n",
    "feature_importances = pd.DataFrame({'feature': list(df_lgb.columns), 'importance': feature_importances}).sort_values('importance', ascending = False)\n",
    "feature_importances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the features with zero importance\n",
    "zero_features = list(feature_importances[feature_importances['importance'] == 0.0]['feature'])\n",
    "#print('There are %d features with 0.0 importance' % len(zero_features))\n",
    "#feature_importances.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(df, threshold = 0.9):\n",
    "\n",
    "    plt.rcParams['font.size'] = 18\n",
    "    \n",
    "    # Sort features according to importance\n",
    "    df = df.sort_values('importance', ascending = False).reset_index()\n",
    "    \n",
    "    # Normalize the feature importances to add up to one\n",
    "    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n",
    "    df['cumulative_importance'] = np.cumsum(df['importance_normalized'])\n",
    "\n",
    "#     # Make a horizontal bar chart of feature importances\n",
    "#     plt.figure(figsize = (10, 6))\n",
    "#     ax = plt.subplot()\n",
    "    \n",
    "#     # Need to reverse the index to plot most important on top\n",
    "#     ax.barh(list(reversed(list(df.index[:15]))), \n",
    "#             df['importance_normalized'].head(15), \n",
    "#             align = 'center', edgecolor = 'k')\n",
    "    \n",
    "#     # Set the yticks and labels\n",
    "#     ax.set_yticks(list(reversed(list(df.index[:15]))))\n",
    "#     ax.set_yticklabels(df['feature'].head(15))\n",
    "    \n",
    "#     # Plot labeling\n",
    "#     plt.xlabel('Normalized Importance'); plt.title('Feature Importances')\n",
    "#     plt.show()\n",
    "    \n",
    "#     # Cumulative importance plot\n",
    "#     plt.figure(figsize = (8, 6))\n",
    "#     plt.plot(list(range(len(df))), df['cumulative_importance'], 'r-')\n",
    "#     plt.xlabel('Number of Features'); plt.ylabel('Cumulative Importance'); \n",
    "#     plt.title('Cumulative Feature Importance');\n",
    "#     plt.show();\n",
    "    \n",
    "    importance_index = np.min(np.where(df['cumulative_importance'] > threshold))\n",
    "#     print('%d features required for %0.2f of cumulative importance' % (importance_index + 1, threshold))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_feature_importances = plot_feature_importances(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the features that have zero importance.\n",
    "df_lgb = df_lgb.drop(columns = zero_features)\n",
    "#print('Dataset shape: ', df_lgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-run the model to see if it identifies any more features with zero importance, (kind of like manual recursive feature eilmination)\n",
    "\n",
    "def identify_zero_importance_features(train, train_labels, iterations = 2):\n",
    "    \n",
    "    #Initialize an empty array to hold feature importances\n",
    "    feature_importances = np.zeros(train.shape[1])\n",
    "\n",
    "    #Create the model with several hyperparameters\n",
    "    model = lgb.LGBMClassifier(objective='binary', boosting_type = 'goss', n_estimators = 10000, class_weight = 'balanced')\n",
    "    \n",
    "    #Fit the model multiple times to avoid overfitting\n",
    "    for i in range(iterations):\n",
    "\n",
    "        #Split into training and validation set\n",
    "        train_features, valid_features, train_y, valid_y = train_test_split(train, train_labels, test_size = 0.25, random_state = i)\n",
    "\n",
    "        # Train using early stopping\n",
    "        model.fit(train_features, train_y, early_stopping_rounds=100, eval_set = [(valid_features, valid_y)], \n",
    "                  eval_metric = 'auc', verbose = 200)\n",
    "\n",
    "        # Record the feature importances\n",
    "        feature_importances += model.feature_importances_ / iterations\n",
    "    \n",
    "    feature_importances = pd.DataFrame({'feature': list(train.columns), 'importance': feature_importances}).sort_values('importance', ascending = False)\n",
    "    \n",
    "    # Find the features with zero importance\n",
    "    zero_features = list(feature_importances[feature_importances['importance'] == 0.0]['feature'])\n",
    "    print('\\nThere are %d features with 0.0 importance' % len(zero_features))\n",
    "    \n",
    "    return zero_features, feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.644206\tvalid_0's binary_logloss: 0.616384\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's auc: 0.627722\tvalid_0's binary_logloss: 0.633327\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's auc: 0.640551\tvalid_0's binary_logloss: 0.632409\n",
      "\n",
      "There are 0 features with 0.0 importance\n"
     ]
    }
   ],
   "source": [
    "second_round_zero_features, feature_importances = identify_zero_importance_features(df_lgb, dataset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#norm_feature_importances = plot_feature_importances(feature_importances, threshold = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Threshold for cumulative importance\n",
    "threshold = 0.95\n",
    "\n",
    "# Extract the features to keep\n",
    "features_to_keep = list(norm_feature_importances[norm_feature_importances['cumulative_importance'] < threshold]['feature'])\n",
    "features_to_keep.append('patient_addmited_to_intensive_care_unit_1_yes_0_no')\n",
    "features_to_keep.append('patient_addmited_to_regular_ward_1_yes_0_no')\n",
    "features_to_keep.append('patient_addmited_to_semi_intensive_unit_1_yes_0_no')\n",
    "features_to_keep.append('patient_id')\n",
    "features_to_keep.append('sars_cov_2_exam_result')\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# Create new datasets with smaller features\n",
    "dataset_small = df_lgb_[features_to_keep]\n",
    "\n",
    "#dataset_small.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# shap_values = shap.TreeExplainer(model).shap_values(valid_features)\n",
    "# shap.summary_plot(shap_values, valid_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#summarize the effects of top features \n",
    "# shap.summary_plot(shap_values[0], valid_features, max_display=30)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset_small\n",
    "features = list(train_df)\n",
    "features.remove('patient_id')\n",
    "features.remove('sars_cov_2_exam_result')\n",
    "features.remove('patient_addmited_to_intensive_care_unit_1_yes_0_no')\n",
    "features.remove('patient_addmited_to_regular_ward_1_yes_0_no')\n",
    "features.remove('patient_addmited_to_semi_intensive_unit_1_yes_0_no')\n",
    "target = 'sars_cov_2_exam_result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train and Validation\n",
    "X_train = train_df.drop('patient_id',axis=1)\n",
    "X_train = X_train.drop(['sars_cov_2_exam_result',\n",
    "                        'patient_addmited_to_regular_ward_1_yes_0_no',\n",
    "                        'patient_addmited_to_semi_intensive_unit_1_yes_0_no',\n",
    "                        'patient_addmited_to_intensive_care_unit_1_yes_0_no'],\n",
    "                       axis=1)\n",
    "target = train_df['sars_cov_2_exam_result']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "                                                  target,\n",
    "                                                  test_size=0.30, \n",
    "                                                  random_state=2020, \n",
    "                                                  stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "                     weights='uniform')\n",
      "model score: 0.874\n",
      "SVC(C=0.025, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      "model score: 0.901\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "model score: 0.888\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "model score: 0.899\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=50, random_state=None)\n",
      "model score: 0.901\n",
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "model score: 0.899\n"
     ]
    }
   ],
   "source": [
    "#model selection\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier()\n",
    "    ]\n",
    "for classifier in classifiers:\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    print(classifier)\n",
    "    print(\"model score: %.3f\" % model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9167088607594936\n",
      "Testing Data Score: 0.8990554899645808\n"
     ]
    }
   ],
   "source": [
    "#looking at Random Forest Classifier alone \n",
    "rf = RandomForestClassifier(n_estimators=2000) \n",
    "rf = rf.fit(X_train, y_train) \n",
    "acc = rf.score(X_val, y_val) \n",
    "print(f\"Training Data Score: {rf.score(X_train, y_train)}\") \n",
    "print(f\"Testing Data Score: {rf.score(X_val, y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization aka find the best set of parameters for the algorithm \n",
    "#create the GridSearchCV model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10,20,30],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "#                           cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                             n_jobs = -1, verbose = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed: 18.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9045569620253164\n",
      "Testing Data Score: 0.9002361275088547\n"
     ]
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_\n",
    "best_grid = grid_search.best_estimator_\n",
    "print(f\"Training Data Score: {best_grid.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {best_grid.score(X_val, y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model_rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-6a1a769307ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#use the best model to predict labels on the test set and print classification report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_best\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_model_rf' is not defined"
     ]
    }
   ],
   "source": [
    "#use the best model to predict labels on the test set and print classification report \n",
    "# y_pred_best = best_model_rf.predict(X_train)\n",
    "# print(classification_report(y_train, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "# import joblib\n",
    "# filename = 'best_model_rf.sav'\n",
    "# joblib.dump(best_model_rf, filename)\n",
    "# filename1 = 'best_model_gnb.sav'\n",
    "# joblib.dump(best_model_gnb, filename1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patient_age_quantile</td>\n",
       "      <td>1238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>respiratory_syncytial_virus</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>influenza_b_rapid_test</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutrophils</td>\n",
       "      <td>64.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hematocrit</td>\n",
       "      <td>61.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>proteina_c_reativa_mg_dl</td>\n",
       "      <td>58.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>urea</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>strepto_a</td>\n",
       "      <td>26.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>potassium</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>serum_glucose</td>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lactic_dehydrogenase</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alanine_transaminase</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gamma_glutamyltransferase</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>total_bilirubin</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>creatine_phosphokinase_cpk</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>arterial_lactic_acid</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pco2_venous_blood_gas_analysis</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ionized_calcium</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature  importance\n",
       "0             patient_age_quantile      1238.0\n",
       "3      respiratory_syncytial_virus       130.0\n",
       "8           influenza_b_rapid_test        92.0\n",
       "4                      neutrophils        64.5\n",
       "1                       hematocrit        61.5\n",
       "6         proteina_c_reativa_mg_dl        58.5\n",
       "5                             urea        38.0\n",
       "13                       strepto_a        26.5\n",
       "7                        potassium        17.5\n",
       "2                    serum_glucose        15.5\n",
       "18            lactic_dehydrogenase        14.5\n",
       "9             alanine_transaminase        14.0\n",
       "10       gamma_glutamyltransferase         7.5\n",
       "11                 total_bilirubin         7.0\n",
       "19      creatine_phosphokinase_cpk         6.5\n",
       "20            arterial_lactic_acid         5.0\n",
       "14  pco2_venous_blood_gas_analysis         4.0\n",
       "12                 ionized_calcium         2.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for dash app figure \n",
    "fig_feature_importances = feature_importances[:18]\n",
    "fig_feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>log10_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patient_age_quantile</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>3.092721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>respiratory_syncytial_virus</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2.113943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>influenza_b_rapid_test</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.963788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutrophils</td>\n",
       "      <td>64.5</td>\n",
       "      <td>1.809560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hematocrit</td>\n",
       "      <td>61.5</td>\n",
       "      <td>1.788875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>proteina_c_reativa_mg_dl</td>\n",
       "      <td>58.5</td>\n",
       "      <td>1.767156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>urea</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.579784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>strepto_a</td>\n",
       "      <td>26.5</td>\n",
       "      <td>1.423246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>potassium</td>\n",
       "      <td>17.5</td>\n",
       "      <td>1.243038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>serum_glucose</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1.190332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lactic_dehydrogenase</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.161368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alanine_transaminase</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.146128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gamma_glutamyltransferase</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.875061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>total_bilirubin</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.845098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>creatine_phosphokinase_cpk</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.812913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>arterial_lactic_acid</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.698970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pco2_venous_blood_gas_analysis</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.602060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ionized_calcium</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.301030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature  importance  log10_value\n",
       "0             patient_age_quantile      1238.0     3.092721\n",
       "3      respiratory_syncytial_virus       130.0     2.113943\n",
       "8           influenza_b_rapid_test        92.0     1.963788\n",
       "4                      neutrophils        64.5     1.809560\n",
       "1                       hematocrit        61.5     1.788875\n",
       "6         proteina_c_reativa_mg_dl        58.5     1.767156\n",
       "5                             urea        38.0     1.579784\n",
       "13                       strepto_a        26.5     1.423246\n",
       "7                        potassium        17.5     1.243038\n",
       "2                    serum_glucose        15.5     1.190332\n",
       "18            lactic_dehydrogenase        14.5     1.161368\n",
       "9             alanine_transaminase        14.0     1.146128\n",
       "10       gamma_glutamyltransferase         7.5     0.875061\n",
       "11                 total_bilirubin         7.0     0.845098\n",
       "19      creatine_phosphokinase_cpk         6.5     0.812913\n",
       "20            arterial_lactic_acid         5.0     0.698970\n",
       "14  pco2_venous_blood_gas_analysis         4.0     0.602060\n",
       "12                 ionized_calcium         2.0     0.301030"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig_feature_importances['log10_value'] = np.log10(fig_feature_importances.loc[:,'importance']) \n",
    "log_features = fig_feature_importances\n",
    "log_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-c36e7e574a00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m fig = go.Figure(go.Bar(\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"log10_value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feature\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             orientation='h'))\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(go.Bar(\n",
    "            x=log_features[\"log10_value\"],\n",
    "            y=log_features[\"feature\"],\n",
    "            orientation='h'))\n",
    "fig.update_layout(yaxis=dict(autorange=\"reversed\"))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
